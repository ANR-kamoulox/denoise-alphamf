%% LyX 2.2.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[10pt]{llncs}
\usepackage[latin9]{inputenc}
\usepackage{verbatim}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amssymb}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\newenvironment{lyxlist}[1]
{\begin{list}{}
{\settowidth{\labelwidth}{#1}
 \setlength{\leftmargin}{\labelwidth}
 \addtolength{\leftmargin}{\labelsep}
 \renewcommand{\makelabel}[1]{##1\hfil}}}
{\end{list}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{multirow}\usepackage{listings}\usepackage{epstopdf}

\makeatother

\begin{document}

\title{Speech Enhancement with Elliptically Stable Residual Component }

\author{Mathieu~Fontaine$^{1}$, Umut \c{S}im\c{s}ekli$^{2}$, Fabian
St\"oter$^{3}$, Antoine~Liutkus$^{3}$, Romain Serizel$^{1}$,
Roland~Badeau$^{2}$}

\institute{$^{1}$Université de Lorraine, CNRS, Inria, Loria, F-54000 Nancy.\\
$^{2}$ LTCI, Télécom ParisTech, Université Paris-Saclay, Paris, France.\\
$^{3}$ Inria and LIRMM, Montpellier, France.}
\maketitle
\begin{abstract}
This paper introduces a new method for multichannel speech enhancement
based on a versatile modeling of the residual noise spectrogram. Such
a single-channel model has already been presented before where the
noise component is assumed to follow an alpha-stable distribution
for each time-frequency~(TF) bin, whereas the speech spectrogram,
supposed to be more regular, is modeled as Gaussian. In this paper,
we describe a multichannel method using the above-mentioned specific
modeling, in which a Monte Carlo Expectation - Maximisation (MCEM)
algorithm is introduced for parameters estimation. In particular,
a multichannel extension of the Itakura-Saito nonnegative matrix factorization
(IS-NMF) is computed in order to estimate covariance matrices of speech,
and a Metropolis-Hastings (MH) algorithm is proposed to estimate the
noise scatter matrix and hence the speech signal.
\end{abstract}


\section{Introduction}

In many contexts, speech denoising is studied and applied in order
to obtain, among other things, a comfortable listening or broadcast
of a talk~\cite{van2009speech}, by exploiting the observed signal
obtained by several microphones. The audio source separation framework
enables us to construct a probabilistic model, where the observed
signal is divided into two latent sources: a noise component and a
target source.

Both are usually considered in the \emph{time-frequency} (TF) domain
where all TF-bins are supposed to be independent and follow a Gaussian
law~\cite{duong_TSALP2010,liutkus2011gaussian}. A common approach
to speech enhancement is the spectral subtraction method~\cite{ephraim1984speech,ephraim1985speech}.
The principle is to estimate an a priori \emph{signal to noise ratio}
(SNR) in order to infer a \emph{short-time spectral amplitude} (STSA)
estimator of the noise which will be subtracted to the STSA of the
observations. Another popular trend was to decompose the \emph{power
spectral densities} (PSD) of sources into a product of two matrices.
The \textit{non-negative matrix factorization} (NMF) model assumes
that the PSDs admit low-rank structures and it performs well in denoising~\cite{sun2015speech}. 

To the best of our knowledge, NMF models in the multichannel case
have been proposed only in a Gaussian probabilistic context, whereas
a non-Gaussian approach could offer a more flexible model for noise
and speech. Moreover, a good initialization in a Gaussian NMF model
is crucial to avoid staying stuck in a local minimum~\cite{Boutsidis2016}.
Many studies in the single-channel case have shown in practice a better
robustness to initialization when the signal is modeled in the TF
domain with as a heavy tail distribution~\cite{yoshii2016student,csimcsekli2015alpha}.

Among this type of distributions, $\alpha$-stable distributions preserve
interesting properties satisfied by Gaussian laws, and they can model
distributions ranging from light tails as in the \emph{Gaussian case}
to heavy tails as in the \emph{Cauchy case}. Indeed, $\alpha$-stable
distributions are the only ones which admit a central limit theorem
and stability by summation~\cite{samoradnitsky1994stable}. Various
studies have been carried out on audio modeling using alpha-stable
processes~\cite{csimcsekli2015alpha,liutkus2015generalized}. Especially
in the TF domain, a generalization of wide-sense stationary (WSS)
processes~\cite{liutkus2011gaussian} has been established in the
$\alpha-$stable case~\cite{liutkus2015generalized} and applied
to noise reduction~\cite{fontaine2017WASPAA}. More precisely, in~\cite{simsekli2018alphastable}
it was considered that the target source is Gaussian and the residual
noise is $\alpha$-stable, in order to get a greater flexibility on
noise modeling.

This paper introduces a generalization of~\cite{simsekli2018alphastable}
to the multichannel case. The goal is to develop an NMF model for
speech assuming that the covariance matrix has a low-rank structure~\cite{duong_TSALP2010},
and we exploit some particular properties of~$\alpha-$stable distributions
in order to estimate their parameters called \emph{scatter matrix}.
In addition, we use Itakura Saito NMF (IS-NMF) extended to the multichannel
case~\cite{sawada2012efficient} in order to obtain an ``hybrid''
NMF decomposition of the Gaussian covariance, plus an $\alpha-$stable
scatter matrix. We will end up investigating the performance of our
method in a realistic framework of multichannel noisy signals, by
comparing it to other state-of-the-art algorithms.

\section{Probabilistic and Filtering models}

\subsection{Mixture model~\label{subsec:Mixture-model}}

Let~$\boldsymbol{x}\in\mathbb{C}^{F\times T\times K}$ be the observed
data in the short-time Fourier transform (STFT) domain where~$F,T$
and~$K$ denote the number of frequency bands, time frames and microphones,
respectively. The observation~$\boldsymbol{x}$ will be assumed to
be the sum of two latent audio sources:~$\boldsymbol{y}\in\mathbb{C}^{F\times T\times K}$
\begin{comment}
Les vecteurs x et y sont tous deux de dimension K, tu te concentres
donc exclusivement sur les mélanges déterminés ?
\end{comment}
to which we assign the meaning of \textit{speech signal }and\textit{~$\boldsymbol{r}\in\mathbb{C}^{F\times T\times K}$
}called the\textit{ residual component. }More precisely, we set for
all time-frequency bins\textit{~$f,t$:}

\begin{equation}
\boldsymbol{x}{}_{ft}=\boldsymbol{y}{}_{ft}+\boldsymbol{r}{}_{ft},\label{eq:mixture_model}
\end{equation}
where each term belongs to~$\mathbb{C}^{K}$. The main goal in this
paper is to estimate~$\boldsymbol{y}$ and~$\boldsymbol{r}$ knowing~$\boldsymbol{x}$,
by using a probabilistic model described below. 

\subsection{Source model}

The voice spectrogram features smooth patterns and generally does
not displays percussive patterns such as finger clapping, broken glass
or drums. For this reason and as in many previous studies, the speech
signal is supposed to be a locally stationary Gaussian process~\cite{liutkus2011gaussian}.
In addition, we assume that each~$\boldsymbol{y}{}_{ft}$ is an isotropic
complex Gaussian vector\footnote{The probability density function (PDF) of an isotropic complex Gaussian
vector is $\mathcal{N}_{C}(\boldsymbol{x}|\mu,\boldsymbol{C})=\frac{1}{\pi^{K}\det\boldsymbol{C}}\exp\left(-\left(\boldsymbol{x}-\mu\right)^{\star}\boldsymbol{C}^{-1}\left(\boldsymbol{x}-\mu\right)\right)$.} of mean~$\boldsymbol{0}$ and a covariance matrix~\textit{$\boldsymbol{C}_{ft}^{\boldsymbol{y}}\triangleq\boldsymbol{R}_{f}v_{f,t}$
}\textit{\emph{with the following NMF decomposition}}\textit{: 
\begin{equation}
\forall f,t\quad\boldsymbol{y}{}_{ft}\sim\mathcal{N}_{c}\left(\boldsymbol{y}{}_{ft};0,\boldsymbol{R}_{f}v_{f,t}\triangleq\boldsymbol{R}_{f}\sum_{l=1}^{L}w_{fl}h_{lt}\right).\label{eq:gaussian_model}
\end{equation}
}where~$\triangleq$ means ``equals by definition'',~$\boldsymbol{R}_{f}\in\mathbb{C}^{K\times K}$
models the spatial characteristics of the speech for the frequency
band~$f$ and~$\boldsymbol{W}\in\mathbb{R}_{+}^{F\times L},\boldsymbol{H}\in\mathbb{R}_{+}^{L\times T}$
are matrices which respectively contain all positive scalars~$w_{fl}$
and $h_{lt}$ .To make notations simpler, let $\boldsymbol{\Theta}\triangleq\left\{ \boldsymbol{W},\boldsymbol{H},\boldsymbol{R}\right\} $
be the parameters to estimate with~$\boldsymbol{R}\triangleq\left\{ \boldsymbol{R}{}_{f}\right\} _{f}$
. 

In contrast to speech signal, the model of the residual component
should admit outliers, reflecting punctual interferences occurring
while recording. To do so, the residual part  is modeled by an heavy-tailed
distribution in the time domain. Recent works proposed a stationary
process called~$\alpha-$harmonizable process with~$\alpha\in(0,2]$
in order to design the residual component in the single-channel case.
It is shown in~\cite{samoradnitsky1994stable,liutkus2015generalized}
that such a model is equivalent to assuming that the signal at every
time-frequency bin~$f,t$ follows a complex isotropic symmetric~$\alpha-$stable
distribution. With the aim of extending the previous model to a multichannel
one, we apply a probabilistic model for~$\boldsymbol{r}$, where
all~$\boldsymbol{r}{}_{ft}$ are assumed to follow an \textit{elliptically
contoured multivariate stable distribution}~(ECMS, denoted~$\mathcal{E}\alpha S$)
and are independent of one another. These distributions, which are
a particular case of~$\alpha-$stable distributions~(see~\cite{samoradnitsky1994stable,leglaive2017alpha}
for a theoretical definition), have the particularity of requiring
only two parameters:
\begin{enumerate}
\item A \textit{characteristic exponent}~$\alpha\in(0,2]$: the smaller
the~$\alpha$, the heavier the tails of the distribution.
\item A positive definite Hermitian\textit{ scatter matrix} in~$\mathbb{C}^{K\times K}$
.
\end{enumerate}
In this article, the scatter matrix are equal to~$\sigma_{f}\boldsymbol{I}_{K}$
, where~$\boldsymbol{I}_{K}\in\mathbb{R}^{K\times K}$ is the identity
matrix and~$\sigma_{f}>0$ is a positive scalar, \emph{i.e.}

\begin{equation}
\forall f,t\quad\boldsymbol{r}{}_{ft}\sim\mathcal{E}\alpha S^{K}\left(\sigma_{f}\boldsymbol{I}_{K}\right).\label{eq:residual_model}
\end{equation}
In our case, we will assume that the noise is relatively stationary
so that the~$\boldsymbol{\sigma}\triangleq\left\{ \sigma_{f}\right\} _{f}$
parameters only depend on the frequency. .

\subsection{Filtering model~\label{subsec:Filtering-model}}

As mentioned in subsection~\ref{subsec:Mixture-model}, we aim to
reconstruct the sources~$\boldsymbol{y}$ and~$\boldsymbol{r}$
from the observed data~$\boldsymbol{x}$. From a signal processing
point of view, when parameters $\boldsymbol{\sigma},\boldsymbol{W},\boldsymbol{H},\boldsymbol{R}$
are supposed to be known, one would like to be able to compute the
Minimum Mean Squared Error (MMSE) estimates of both sources. In our
probabilistic context, the MMSE estimates can be expressed as the
posteriori expectations~$\mathbb{E}\left(\boldsymbol{y}{}_{ft}|\boldsymbol{x}{}_{ft},\boldsymbol{\Theta},\boldsymbol{\sigma}\right)$.

To address this issue, a property specific to ECMS distributions makes
it possible to represent~$\boldsymbol{r}$ as a complex normal distribution~$\mathcal{N}_{c}$
of dimension~$K$, whose variance is controlled by a positive random
variable~$\phi{}_{ft}$ distributed as $\mathcal{P}\frac{\alpha}{2}S\left(2\cos\left(\frac{\pi\alpha}{4}\right)^{2/\alpha}\right)$,
where~$\mathcal{P}\frac{\alpha}{2}S$ is the \emph{positive $\alpha/2$-stable
distribution} (see~\cite{csimcsekli2015alpha} for more details):

\begin{equation}
\forall f,t\quad\boldsymbol{r}{}_{ft}|\phi{}_{ft}\sim\mathcal{N}_{c}\left(\boldsymbol{r}{}_{ft};0,\phi{}_{ft}\sigma_{f}\boldsymbol{I}_{k}\right),\label{eq:conditionnal_gaussian}
\end{equation}
Since $\phi{}_{ft}$ depends on the characteristic exponent~$\alpha$,
it is called \emph{impulse variable}. Using the conditional Gaussianity
in~\eqref{eq:conditionnal_gaussian}, the Gaussian summation stability,
and assuming that ~$\boldsymbol{\Phi}\triangleq\left\{ \phi{}_{ft}\right\} _{f,t}$
are known, we get:

\begin{equation}
\forall f,t\quad\boldsymbol{x}{}_{ft}|\phi{}_{ft}\sim\mathcal{N}_{c}\left(\boldsymbol{x}{}_{ft};\,0,\boldsymbol{C}_{ft}^{\boldsymbol{x}|\phi}\right),\label{eq:observation_phi}
\end{equation}
where $\boldsymbol{C}_{ft}^{\boldsymbol{x}|\phi}\triangleq\boldsymbol{R}_{f}\sum_{l=1}^{L}w_{fl}h_{lt}+\phi{}_{ft}\sigma_{f}\boldsymbol{I}_{k}$.
Thus, we can build a multichannel parametric Wiener filter~\cite{van2009speech}:

\begin{equation}
\mathbb{E}\left(\boldsymbol{y}{}_{ft}|\boldsymbol{x}{}_{ft},\boldsymbol{\Phi},\boldsymbol{\Theta},\boldsymbol{\sigma}\right)=\boldsymbol{G}_{ft}\boldsymbol{x}{}_{ft},\label{eq:Wiener_filtering}
\end{equation}
with~$.^{-1}$ the inverse matrix operator and where ~$\boldsymbol{G}_{ft}\triangleq\boldsymbol{C}_{ft}^{\boldsymbol{y}}\left(\boldsymbol{C}_{ft}^{\boldsymbol{x}|\phi}\right)^{-1}$. 

\section{Parameter Estimation ~\label{sec:Parameter-Estimation}}

\subsection{Expectation-Maximization (EM) algorithm}

Assuming that the observations~$\boldsymbol{x}$ and the impulse
variable~$\boldsymbol{\phi}$ are known, we first aim to estimate
the parameters~$\boldsymbol{\Theta}$ . We choose the maximum likelihood
estimator in order to get the most probable $\boldsymbol{W},\boldsymbol{H}$
matrices in our NMF model and~$\boldsymbol{R}$:

\begin{equation}
\left(\boldsymbol{W}^{\star},\boldsymbol{H}^{\star},\boldsymbol{R}^{\star}\right)=\arg\max_{\boldsymbol{W},\boldsymbol{H},\boldsymbol{R}}\log\mathbb{P}\left(\boldsymbol{x},\boldsymbol{\Phi}\,|\,\boldsymbol{\Theta},\boldsymbol{\sigma}\right),\label{eq:maximum_likelihood}
\end{equation}
where~$\boldsymbol{\Phi}$ is a latent variable and~$\log\mathbb{P}\left(\boldsymbol{x},\boldsymbol{\Phi}\,|\,\boldsymbol{\Theta},\boldsymbol{\sigma}\right)$
is the log-likelihood. As in~\cite{simsekli2018alphastable}, we
propose an EM algorithm. This method aims to minimize an upper-bound
of ~$\mathcal{L}_{n}\left(\boldsymbol{W},\boldsymbol{H},\boldsymbol{R}\right)=-\log\mathbb{P}\left(\boldsymbol{x},\boldsymbol{\Phi}\,|\,\boldsymbol{\Theta},\boldsymbol{\sigma}\right)$.
This approach is summarized in the following two steps:

\begin{align}
\text{E-Step: }\qquad & \mathcal{Q}_{n}\left(\boldsymbol{W},\boldsymbol{H},\boldsymbol{R}\right)=-\mathbb{E}_{\boldsymbol{\Phi}|\boldsymbol{x},\boldsymbol{W}^{\left(n-1\right)},\boldsymbol{H}^{\left(n-1\right)}}\left[\mathcal{L}_{n}\left(\boldsymbol{W},\boldsymbol{H},\boldsymbol{R}\right)\right],\label{eq:E-Step}\\
\text{M-Step: }\qquad & \left(\boldsymbol{W}^{\left(n\right)},\boldsymbol{H}^{\left(n\right)},\boldsymbol{R}^{\left(n\right)}\right)=\arg\max_{\boldsymbol{W},\boldsymbol{H},\boldsymbol{R}}\mathcal{Q}_{n}\left(\boldsymbol{W},\boldsymbol{H},\boldsymbol{R}\right).\label{eq:M-Step}
\end{align}
For the sake of conciseness, we will use~$\mathbb{E}_{\boldsymbol{\Phi}}$
instead of~$\mathbb{E}_{\boldsymbol{\Phi}|\boldsymbol{x},\boldsymbol{W}^{\left(n\right)},\boldsymbol{H}^{\left(n\right)}}$.

\subsubsection*{E-Step:~ }

We first try to figure out a positive function that maximizes the
negative log-likelihood function $\mathcal{L}_{n}\left(\boldsymbol{W},\boldsymbol{H},\boldsymbol{R}\right)$
which is equals to~\cite{sawada2012efficient}:

\begin{equation}
\mathcal{L}_{n}\left(\boldsymbol{W},\boldsymbol{H},\boldsymbol{R}\right)=\sum_{f,t}\left[\text{tr}\left(\tilde{\boldsymbol{X}}{}_{ft}\left(\boldsymbol{C}_{ft}^{\boldsymbol{x}|\phi}\right)^{-1}\right)+\log\det\boldsymbol{C}_{ft}^{\boldsymbol{x}|\phi}\right]\label{eq:log_likelihood}
\end{equation}
where~$\tilde{\boldsymbol{X}}{}_{ft}\triangleq\boldsymbol{x}{}_{ft}\boldsymbol{x}_{ft}^{\star}$
and $.^{\star}$ stands for the Hermitian transposition. A positive
auxiliary function~$\mathcal{L}_{n}^{+}$ which satisfies:

\begin{equation}
\mathcal{L}_{n}^{+}\left(\boldsymbol{W},\boldsymbol{H},\boldsymbol{R},\boldsymbol{U},\boldsymbol{V}\right)\geq\mathcal{L}_{n}\left(\boldsymbol{W},\boldsymbol{H},\boldsymbol{R}\right)\label{eq:aux_function}
\end{equation}
is introduced in~\cite{sawada2012efficient}. Using~\eqref{eq:aux_function}
and the definition of~$\mathcal{Q}_{n}$ in~\eqref{eq:E-Step},
we obtain:

\begin{equation}
\mathbb{E}_{\boldsymbol{\Phi}}\mathcal{L}_{n}\left(.\right)\leq\mathbb{E}_{\boldsymbol{\Phi}}\mathcal{L}_{n}^{+}\left(.\right)\triangleq\mathcal{Q}_{n}^{+}\left(.\right)\label{eq:inequality_function}
\end{equation}
with:

\textit{\footnotesize{}
\begin{align}
\mathcal{Q}_{n}^{+}\left(\boldsymbol{W},\boldsymbol{H},\boldsymbol{R},\boldsymbol{U},\boldsymbol{V}\right)=\sum_{f,t}\bigg[\sum_{l}\frac{\mathbb{E}_{\boldsymbol{\Phi}}\left(\text{tr}\left[\tilde{\boldsymbol{X}}{}_{ft}\boldsymbol{U}_{lft}\left(\boldsymbol{C}_{ft}^{\boldsymbol{x}|\phi}\right)^{-1}\boldsymbol{U}_{lft}\right]\right)}{w_{fl}h_{lt}}\nonumber \\
+\mathbb{E}_{\boldsymbol{\Phi}}\left(\text{tr}\left[\tilde{\boldsymbol{X}}{}_{ft}\boldsymbol{U}_{rft}^{2}\right]\right)\sigma_{f}^{-1}\phi_{ft}^{-1}+\mathbb{E}_{\boldsymbol{\Phi}}\left(\log\det\boldsymbol{V}_{ft}+\det\left(\boldsymbol{V}_{ft}^{-1}\boldsymbol{C}_{ft}^{\boldsymbol{x}|\phi}\right)-1\right)\bigg]\label{eq:positive_Estep}
\end{align}
 }The form in~\eqref{eq:positive_Estep} admits partial derivatives
that will be useful as part of a multiplicative update~\cite{fevotte2011algorithms}
in the M-Step.

\subsubsection*{M-Step:~}

Solving the M-Step in~\eqref{eq:M-Step} is equivalent to zeroing
the partial derivatives~$\frac{\partial\mathcal{Q}_{n}^{+}}{\partial w_{fl}}$
and~$\frac{\partial\mathcal{Q}_{n}^{+}}{\partial h_{lt}}$ and to
set~$\boldsymbol{U},\boldsymbol{V}$ such that the equality in~\eqref{eq:inequality_function}
is verified. A multiplicative update approach yields:

\begin{align}
w_{fl} & \leftarrow w_{fl}\sqrt{\frac{\sum_{t}h_{lt}\text{tr}\left(\boldsymbol{R}_{f}\boldsymbol{P}{}_{ft}\right)}{\sum_{t}h_{lt}\text{tr}\left(\boldsymbol{R}_{f}\boldsymbol{\Xi}{}_{ft}\right)}}\label{eq:update_w}\\
h_{lt} & \leftarrow h_{lt}\sqrt{\frac{\sum_{f}w_{fl}\text{tr}\left(\boldsymbol{R}_{f}\boldsymbol{P}{}_{ft}\right)}{\sum_{f}w_{fl}\text{tr}\left(\boldsymbol{R}_{f}\boldsymbol{\Xi}{}_{ft}\right)}}\label{eq:update_h}
\end{align}
where $\boldsymbol{\boldsymbol{\Xi}}{}_{ft}=\mathbb{E}_{\boldsymbol{\Phi}}\left[\left(\boldsymbol{C}_{ft}^{\boldsymbol{x}|\varphi_{i}}\right)^{-1}\right]$
and~{\small{}$\boldsymbol{P}{}_{ft}=\mathbb{E}_{\boldsymbol{\Phi}}\left[\left(\boldsymbol{C}_{ft}^{\boldsymbol{x}|\varphi_{i}}\right)^{-1}\tilde{\boldsymbol{X}}{}_{ft}\left(\boldsymbol{C}_{ft}^{\boldsymbol{x}|\varphi_{i}}\right)^{-1}\right]$}.
We will explain how to compute these expectations in subsection~\ref{subsec:Expectation-estimation-using}.

\subsection{Updating of spatial covariance matrices and scatter matrices~\label{subsec:Update-of-the} }

The update of~$\boldsymbol{R}$ is given by the EM approach in~\cite{duong_TSALP2010}.
Moreover, for a better numerical stability, we will use the trick
proposed in~\cite{nugraha2016multichannel} which is an update equivalent
to that of~\cite{duong_TSALP2010}:

\begin{equation}
\boldsymbol{R}_{f}\leftarrow\left(\sum_{t}v\left(f,t\right)\right)^{-1}\times\sum_{t}\left(\boldsymbol{C}_{ft}^{\boldsymbol{yy}^{\star}|\boldsymbol{x}}\right),\label{eq:R_update}
\end{equation}
where: $\boldsymbol{C}_{ft}^{\boldsymbol{yy}^{\star}|\boldsymbol{x}}\triangleq\boldsymbol{G}_{ft}\tilde{\boldsymbol{X}}{}_{ft}\boldsymbol{G}_{ft}+\boldsymbol{C}_{ft}^{\boldsymbol{y}}-\boldsymbol{G}_{ft}\boldsymbol{C}_{ft}^{\boldsymbol{y}}$.

The estimation of positive scalars~$\boldsymbol{\sigma}$ are inspired
by a result in~\cite{cambanis1983alpha} linking the mean energy
over a small fraction of an $\alpha-$harmonizable process and~$\boldsymbol{\sigma}$.
To emphasize that our noise is relatively stationary compared to the
speech signal, we use the median instead of the arithmetic mean. To
summarize:

\begin{equation}
\mathbb{M}\left(\Vert\sum_{t}\boldsymbol{x}\left(f,t\right)\Vert^{\alpha/2}\right)^{2}\propto\sqrt{\sigma_{f}},\label{eq:update_sigma}
\end{equation}
where~$\propto$ means ``proportional to''. Since those parameters
depend only on observations, they will be estimated at the beginning
of the algorithm. 

\subsection{Expectation estimation using Metropolis-Hastings algorithm~\label{subsec:Expectation-estimation-using}}

We still have to calculate the expectations~$\boldsymbol{\Xi}{}_{ft}$
and~$\boldsymbol{P}{}_{ft}$. Unfortunately, they cannot be calculated
analytically. To address this issue, we set up a Markov Chain Monte
Carlo (MCMC) algorithm in order to approximate the expectations for
each iteration. We are focusing on the Metropolis-Hastings algorithm
through an empirical estimation of $\boldsymbol{\Xi}{}_{ft}$ and~$\boldsymbol{P}{}_{ft}$
as follows:

\begin{align}
\overline{\boldsymbol{\Xi}}{}_{ft} & \simeq\frac{1}{I}\sum_{i=1}^{I}\left(\boldsymbol{C}_{ft}^{\boldsymbol{x}|\varphi_{i}}\right)^{-1}\label{eq:Xi}\\
\overline{\boldsymbol{P}}{}_{ft} & \simeq\frac{1}{I}\sum_{i=1}^{I}\left(\left(\boldsymbol{C}_{ft}^{\boldsymbol{x}|\varphi_{i}}\right)^{-1}\tilde{\boldsymbol{X}}{}_{ft}\left(\boldsymbol{C}_{ft}^{\boldsymbol{x}|\varphi_{i}}\right)^{-1}\right)\label{eq:P}
\end{align}
with~$\left(\boldsymbol{C}_{ft}^{\boldsymbol{x}|\varphi_{i}}\right)^{-1}=\left[\sum_{l}\left(\boldsymbol{R}_{fl}w_{fl}h_{lt}\right)+\varphi_{ft,\,i}\sigma_{f}\boldsymbol{I}_{k}\right]^{-1}$
and $\varphi_{ft,\,i}$ are sampled as follows:

\subsubsection*{First Step (Sampling process):}

Generate a sampling via the prior distribution $\varphi'_{ft}\sim\mathcal{P}\frac{\alpha}{2}S\left(2\cos\left(\frac{\pi\alpha}{4}\right)^{2/\alpha}\right)$.

\subsubsection*{Second Step (Acceptance):}
\begin{itemize}
\item Draw $u\sim\mathcal{U}\left(\left[0,1\right]\right)$ where~$\mathcal{U}$
denotes the uniform distribution. 
\item Compute the following acceptance probability:
\[
\text{acc}\left(\varphi{}_{ft}\rightarrow\varphi'{}_{ft}\right)=\min\left(1,\frac{\mathcal{N}_{c}\left(\boldsymbol{x}{}_{ft};0,\,\varphi'{}_{ft}\sigma_{f}\boldsymbol{I}_{K}+\boldsymbol{C}_{ft}^{\boldsymbol{y}}\right)}{\mathcal{N}_{c}\left(\boldsymbol{x}{}_{ft};0,\,\varphi{}_{ft}\sigma_{f}\boldsymbol{I}_{K}+\boldsymbol{C}_{ft}^{\boldsymbol{y}}\right)}\right)
\]
\item Test the acceptance: 
\begin{itemize}
\item if~$u<\text{acc}\left(\varphi{}_{ft,\,i-1}\rightarrow\varphi'{}_{ft}\right)$,
then~$\varphi{}_{ft,\,i}=\varphi'{}_{ft}$~(acceptance)
\item otherwise, $\varphi{}_{ft,\,i}=\varphi{}_{ft,\,i-1}$~(rejection)
\end{itemize}
\end{itemize}
Algorithm~\ref{alg:Denoising-Algorithm} summarizes our proposed
method for denoising. 

\begin{algorithm}[H]
\begin{enumerate}
\item \textbf{Inputs} 

$\boldsymbol{W},\,\boldsymbol{H},\,\boldsymbol{R},\,N,\,I$\\
\item \textbf{Initialization}

Compute~$\boldsymbol{\sigma}$ as in~\eqref{eq:update_sigma}.\\
\item \textbf{EM algorithm }
\begin{description}
\item [{for}] $n=1,\dots,N$ \textbf{do}\\
\textbf{}\\
\textsf{//E-Step}
\begin{description}
\item [{for}] $i=1,\dots,I$ \textbf{do}
\begin{description}
\item [{Draw~$\varphi_{i}{}_{ft}$}] via Metropolis-Hastings algorithm
(subsection~\ref{subsec:Expectation-estimation-using})\vspace{0.1cm}
\item [{Compute}] $\overline{\boldsymbol{\Xi}}$~\eqref{eq:Xi} and $\overline{\boldsymbol{P}}$~\eqref{eq:P}\\
\end{description}
\end{description}
\textsf{//M-Step}
\begin{description}
\item [{while}] not converged \textbf{do}
\begin{description}
\item [{Update}] $\boldsymbol{W}$~\eqref{eq:update_w},~$\boldsymbol{H}$~\eqref{eq:update_h}
and $\boldsymbol{R}$~\eqref{eq:R_update}\\
\end{description}
\end{description}
\end{description}
\item \textbf{Image Source reconstruction} \label{enu:Source reconstruction}

\begin{description}
\item [{Compute}] $\boldsymbol{C}_{ft}^{\boldsymbol{y}}\boldsymbol{\bar{\boldsymbol{\boldsymbol{\Xi}}}}{}_{ft}\boldsymbol{x}{}_{ft}$
in order to obtain~$\boldsymbol{y}$\\
\end{description}
\item \textbf{Speech Signal Reconstruction\label{enu:Speech-Signal-Reconstruction} }
\begin{description}
\item [{Set}] $\boldsymbol{U}_{f}$ as the principal eigenvector of~$\frac{1}{T}\sum_{t}\boldsymbol{C}_{ft}^{\boldsymbol{yy}^{\star}|\boldsymbol{x}}$
\item [{Compute}] $\hat{\boldsymbol{s}}_{ft}=\boldsymbol{U}_{f}^{\star}\hat{\boldsymbol{y}}_{ft}$
\end{description}
\end{enumerate}
\caption{Denoising Algorithm\label{alg:Denoising-Algorithm}}
\end{algorithm}
The step~\ref{enu:Speech-Signal-Reconstruction} in the algorithm~\ref{alg:Denoising-Algorithm},
which is explained in section~\ref{sec:Single-Channel-Speech-Signal},
can be interpreted as a beamforming technique where only the \emph{direction
of arrival} (DOA) with the maximum energy is considered~\cite{van1988beamforming}. 

\section{Single-Channel Speech Signal Reconstruction\label{sec:Single-Channel-Speech-Signal}}

Let~$\hat{\boldsymbol{y}}$ denotes multichannel signal obtain thanks
to step~\ref{enu:Source reconstruction} of Algorithm~\ref{alg:Denoising-Algorithm}.
In the context of speech enhancement, the desired speech is a single-channel
signal. Let us note this signal $\widehat{\boldsymbol{s}}\in\mathbb{C}^{F\times T}$.
We will assume as in~\cite{van1988beamforming} that $\hat{\boldsymbol{s}}$
is a linear combination of~$\hat{\boldsymbol{y}}$ as follows:

\[
\hat{\boldsymbol{s}}_{ft}=\boldsymbol{U}_{f}^{\star}\hat{\boldsymbol{y}}_{ft}.
\]
In order to estimate~$\boldsymbol{U}_{f}\in\mathbb{C}^{K}$, we are
looking to maximize the energy of~$\boldsymbol{y}$ for all frequency
band~$f$. This means maximizing: 

\begin{align*}
\frac{1}{T}\sum_{t}\mathbb{E}\left(\left|\hat{\boldsymbol{s}}_{ft}\right|^{2}|\boldsymbol{x}_{ft}\right) & =\boldsymbol{U}_{f}^{\star}\mathbb{E}\left(\boldsymbol{y}_{ft}\boldsymbol{y}_{ft}^{\star}|\boldsymbol{x}\right)\boldsymbol{U}_{f}.\\
 & =\boldsymbol{U}_{f}^{\star}\frac{1}{T}\sum_{t}\left(\boldsymbol{C}_{ft}^{\boldsymbol{yy}^{\star}|\boldsymbol{x}}\right)\boldsymbol{U}_{f}
\end{align*}
 The solution of this optimization problem is that~$\boldsymbol{U}_{f}$
is the eigenvector associated to the largest eigenvalue of the Hermitian
matrix~$\frac{1}{T}\sum_{t}\left(\boldsymbol{C}_{ft}^{\boldsymbol{yy}^{\star}|\boldsymbol{x}}\right)$
~\cite{duong_TSALP2010}. 

\section{Evaluation}

We investigate both the quality of speech enhancement and on audio
source separation performance. Our proposed approach will be compared
to both baseline methods:
\begin{lyxlist}{00.00.0000}
\item [{\textbf{ARC}}] Our proposed method: alpha residual component~(ARC)
which mixed a Gaussian component plus an~$\alpha-$stable noise.
It will be considered $N=...$ iterations for the EM part ,$I=...$
for the MH part and~$\alpha=...$.
\item [{\textbf{MWF}}] The classic multi-channel Wiener filter~(MWF)~\cite{benesty2008noncausal}
which assumes that both noise and speech are Gaussian in the time-frequency
domain. The multichannel Wiener filter is defined as the best estimator
minimizing the mean squared error~(MSE) between the estimated and
the ground truth source.
\item [{\textbf{GEVD}}] The generalized eigenvalue decomposition~(GEVD)
multichannel Wi-\\
ener filtrer \cite{serizel2014low} is based on low-rank approximation
of autocorrelation matrix of the speech signal in order to provide
a more robust noise reduction.
\end{lyxlist}
The corpus for evaluation is made up of mono speech excerpts in~Librispeech~\cite{panayotov2015librispeech}
with a sample rate of~$16\,kHz$. They are placed end-to-end with
several silence periods for a total length of ~$3$ minutes and assembled
with three different environmental noise taken from Aurora~\cite{hirsch2000aurora}:
babble noise, restaurant and train. We apply on both signals a STFT
using a Hann window with an FFT length of~$1024$ and~$50\%$ overlap.

Those excerpts are further convoluted with different room impulse
responses (RIR) provided by~Roomsimove in order to get reverberant
stereophonic signals. The room dimensions are $5\times4\times3$ meters
and reverberation times, based on a 60dB decay (RT60), are $0,\,250\,\text{and}\,500\,mS$.
For more challenges, two spatial settings and~$3$ signal-to-noise
(SNR) ratio will be proposed. The different SNR values are~$-5,\,0,\,5\,dB$
and the spatial configurations are an angular difference of~$30^{\circ}$or~$90^{\circ}$~between
both sources. In short, a total of~$54$ noisy sources have been
denoised by the three proposed methods.

For the evaluation, three scores will be measured: one determines
the audio separation quality (BSS source~\cite{vincent2006performance}),
another is an intelligibility weighted spectral distortion (SIW-SD)~\cite{serizel2014low}
measure and the last one is a speech intelligibility-weighted SNR
(SIW-SNR)~\cite{greenberg1993intelligibility}. 
\begin{description}
\item [{Acknowledgments.}] This work was partly supported by the research
programme KAMoulox (ANR-15-CE38-0003-01) and EDiSon3D (ANR-13-CORD-0008-01)
funded by ANR, the French State agency for research.
\end{description}
\bibliographystyle{splncs03}
\bibliography{IEEEabrv,LVA-ICA2018}

\end{document}
